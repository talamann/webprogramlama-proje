import os
from deep_translator import GoogleTranslator
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Model ve tokenizer'Ä± bir kez yÃ¼kle
model_name = "roberta-base-openai-detector"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Metin dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r
folder_path = r"metinler"

# TÃ¼m .txt dosyalarÄ±nÄ± sÄ±rayla iÅŸle
for filename in os.listdir(folder_path):
    if filename.endswith(".txt"):
        file_path = os.path.join(folder_path, filename)
        
        with open(file_path, "r", encoding="utf-8") as f:
            turkish_text = f.read().strip()

        print(f"File: {filename}")
        print(f"Original (TR): {turkish_text}")

        try:
            # TÃ¼rkÃ§eyi Ä°ngilizceye Ã§evir
            english_text = GoogleTranslator(source='tr', target='en').translate(turkish_text)
            print(f"ingilizceye Ã§evrildi (EN): {english_text}")

            # Tokenize et
            inputs = tokenizer(english_text, return_tensors="pt", truncation=True)

            # Tahmin yap
            with torch.no_grad():
                outputs = model(**inputs)

            # OlasÄ±lÄ±klarÄ± hesapla
            probs = torch.softmax(outputs.logits, dim=1)
            human_prob = probs[0][0].item()
            ai_prob = probs[0][1].item()

            print(f"ğŸ¤– AI ile yazilmis olma olasligi: {ai_prob:.4f}")
            print(f"ğŸ‘¤ insan tarafÄ±ndan yazilmis olma olasiligi: {human_prob:.4f}")

        except Exception as e:
            print(f"âš ï¸ Error processing {filename}: {e}")
